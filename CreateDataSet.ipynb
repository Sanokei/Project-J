{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI powered Highlight Clipper\n",
    "Use the whisper API to get transcipts and then use ChatGPT for sentiment analysis to get if its interesting or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytube in c:\\python311\\lib\\site-packages (12.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3 -> 23.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: youtube-dl in c:\\python311\\lib\\site-packages (2021.12.17)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3 -> 23.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\python311\\lib\\site-packages (0.27.0)\n",
      "Requirement already satisfied: requests>=2.20 in c:\\python311\\lib\\site-packages (from openai) (2.28.2)\n",
      "Requirement already satisfied: tqdm in c:\\python311\\lib\\site-packages (from openai) (4.64.1)\n",
      "Requirement already satisfied: aiohttp in c:\\python311\\lib\\site-packages (from openai) (3.8.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\python311\\lib\\site-packages (from requests>=2.20->openai) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python311\\lib\\site-packages (from requests>=2.20->openai) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\python311\\lib\\site-packages (from requests>=2.20->openai) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python311\\lib\\site-packages (from requests>=2.20->openai) (2022.12.7)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\python311\\lib\\site-packages (from aiohttp->openai) (22.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\python311\\lib\\site-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\python311\\lib\\site-packages (from aiohttp->openai) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\python311\\lib\\site-packages (from aiohttp->openai) (1.8.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\python311\\lib\\site-packages (from aiohttp->openai) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\python311\\lib\\site-packages (from aiohttp->openai) (1.3.1)\n",
      "Requirement already satisfied: colorama in c:\\python311\\lib\\site-packages (from tqdm->openai) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3 -> 23.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: moviepy in c:\\python311\\lib\\site-packages (1.0.3)\n",
      "Requirement already satisfied: decorator<5.0,>=4.0.2 in c:\\python311\\lib\\site-packages (from moviepy) (4.4.2)\n",
      "Requirement already satisfied: tqdm<5.0,>=4.11.2 in c:\\python311\\lib\\site-packages (from moviepy) (4.64.1)\n",
      "Requirement already satisfied: requests<3.0,>=2.8.1 in c:\\python311\\lib\\site-packages (from moviepy) (2.28.2)\n",
      "Requirement already satisfied: proglog<=1.0.0 in c:\\python311\\lib\\site-packages (from moviepy) (0.1.10)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\python311\\lib\\site-packages (from moviepy) (1.24.2)\n",
      "Requirement already satisfied: imageio<3.0,>=2.5 in c:\\python311\\lib\\site-packages (from moviepy) (2.26.0)\n",
      "Requirement already satisfied: imageio_ffmpeg>=0.2.0 in c:\\python311\\lib\\site-packages (from moviepy) (0.4.8)\n",
      "Requirement already satisfied: pillow>=8.3.2 in c:\\python311\\lib\\site-packages (from imageio<3.0,>=2.5->moviepy) (9.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\python311\\lib\\site-packages (from requests<3.0,>=2.8.1->moviepy) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python311\\lib\\site-packages (from requests<3.0,>=2.8.1->moviepy) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\python311\\lib\\site-packages (from requests<3.0,>=2.8.1->moviepy) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python311\\lib\\site-packages (from requests<3.0,>=2.8.1->moviepy) (2022.12.7)\n",
      "Requirement already satisfied: colorama in c:\\python311\\lib\\site-packages (from tqdm<5.0,>=4.11.2->moviepy) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3 -> 23.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install pytube\n",
    "%pip install youtube-dl\n",
    "%pip install openai\n",
    "%pip install moviepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import config\n",
    "\n",
    "import pytube\n",
    "\n",
    "import requests\n",
    "import subprocess\n",
    "import os\n",
    "import shutil\n",
    "import ast\n",
    "\n",
    "import openai\n",
    "\n",
    "from moviepy.editor import VideoFileClip, concatenate_videoclips\n",
    "from moviepy.audio.io.AudioFileClip import AudioFileClip\n",
    "\n",
    "import youtube_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = config.OAI_API_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YouTube video URL\n",
    "vid_url = \"https://youtu.be/9fvETktnaRw\"\n",
    "fps = 30\n",
    "\n",
    "# how long the testing clips should be\n",
    "testing_clips_time = 20\n",
    "\n",
    "# How high the sentiment has to be for it to be in the video\n",
    "sentiment_score = 0.6\n",
    "max_token_count = 3000\n",
    "custom_prompt = \"entertaining a casual viewer of Youtube would find the sentence as part of a video\"\n",
    "\n",
    "# debug\n",
    "delete_directories = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the audio stream\n",
    "try:\n",
    "    video_stream = pytube.YouTube(vid_url).streams.filter(only_audio=True).first()\n",
    "except:\n",
    "    video_stream = pytube.YouTube(vid_url).streams.filter(progressive=True).order_by('resolution').first()\n",
    "\n",
    "# Check if audio stream is not None before attempting to download it\n",
    "if video_stream is not None:\n",
    "    # Download the audio stream\n",
    "    audio_file = video_stream.download(filename=\"input.mp4\").replace(\"\\\\\",\"/\")\n",
    "else:\n",
    "    print(\"No audio stream found.\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Break the video down into 25mb chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_video_by_seconds(input_file_path, chunk_duration):\n",
    "    \"\"\"\n",
    "    Splits a video file into smaller chunks using ffmpeg.\n",
    "    \"\"\"\n",
    "    # Get the duration of the input video\n",
    "    duration_command = [\"ffprobe\", \"-i\", input_file_path, \"-show_entries\", \"format=duration\", \"-v\", \"quiet\", \"-of\", \"csv=p=0\"]\n",
    "    duration_output = subprocess.check_output(duration_command, encoding=\"utf-8\")\n",
    "    input_duration = float(duration_output.strip())\n",
    "\n",
    "    # Calculate the number of chunks and their start and end times\n",
    "    chunk_start_times = range(0, int(input_duration), int(chunk_duration))\n",
    "    chunk_end_times = [min(start_time + chunk_duration, input_duration) for start_time in chunk_start_times]\n",
    "\n",
    "    # Split the video into chunks using ffmpeg\n",
    "    for i, (start_time, end_time) in enumerate(zip(chunk_start_times, chunk_end_times)):\n",
    "        output_file_path = f\"downloads/input_{i}.mp4\"\n",
    "        split_command = [\"ffmpeg\", \"-i\", input_file_path, \"-ss\", str(start_time), \"-to\", str(end_time), \"-c\", \"copy\", output_file_path]\n",
    "        subprocess.run(split_command, check=True)\n",
    "\n",
    "newpath = os.getcwd() + \"/downloads/\"\n",
    "if not os.path.exists(newpath):\n",
    "    os.makedirs(newpath)\n",
    "    \n",
    "input_file_path = 'input.mp4'\n",
    "split_video_by_seconds(input_file_path, testing_clips_time)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create metadata for the files <br/>\n",
    "<sub>Start time and duration</sub>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "newpath = os.getcwd() + \"/metadata/\"\n",
    "if not os.path.exists(newpath):\n",
    "    os.makedirs(newpath)\n",
    "\n",
    "start_time = 0.0\n",
    "\n",
    "for i, filename in enumerate(os.listdir('downloads')):\n",
    "    md_output_file_path = f\"metadata/input_{i}.txt\"\n",
    "    with open(md_output_file_path, 'w') as output_file:\n",
    "        clip = AudioFileClip('downloads/'+filename)\n",
    "        duration = clip.duration\n",
    "        clip.close()\n",
    "        output_file.write(f\"[{start_time},{duration}]\")\n",
    "        start_time += duration"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input the audio into Whisper and get transcription\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "newpath = os.getcwd() + \"/sentences/\"\n",
    "if not os.path.exists(newpath):\n",
    "    os.makedirs(newpath)\n",
    "\n",
    "url = 'https://api.openai.com/v1/audio/transcriptions'\n",
    "headers = {\n",
    "    'Authorization': f'Bearer {config.OAI_API_TOKEN}'\n",
    "}\n",
    "data = {\n",
    "    'model':'whisper-1',\n",
    "    'prompt':'Woah! I for a fact don\\'t believe that... Okay, I know. I love those~'\n",
    "}\n",
    "for chunk_num, filename in enumerate(os.listdir('downloads')):\n",
    "    with open(\"downloads/\" + filename, \"rb\") as input_file:\n",
    "        files = {\n",
    "            'file':(filename,input_file)\n",
    "        }\n",
    "        transcription = requests.post(url=url, headers=headers, files=files, data=data)\n",
    "        output_file_path = f\"sentences/input_{chunk_num}.txt\"\n",
    "        with open(output_file_path, 'w', encoding=\"utf-8\") as output_file:\n",
    "            output_file.write(transcription.json().get('text'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ChatGPT Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://api.openai.com/v1/chat/completions'\n",
    "headers = {\n",
    "    'Authorization': f'Bearer {config.OAI_API_TOKEN}'\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Breakdown the text to the max_token_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "newpath = os.getcwd() + \"/temporary/\"\n",
    "if not os.path.exists(newpath):\n",
    "    os.makedirs(newpath)\n",
    "\n",
    "chunk_num = 0\n",
    "for filename in os.listdir('sentences'):\n",
    "    with open(\"sentences/\" + filename, \"r\", encoding=\"utf-8\") as chunk_file, \\\n",
    "         open(\"metadata/\" + filename, \"r\", encoding=\"utf-8\") as timestamp_file:\n",
    "        chunk = chunk_file.read().strip() # read the entire chunk into memory\n",
    "        timestamp = timestamp_file.read().strip() # read the entire timestamp into memory\n",
    "        \n",
    "        if not chunk: # skip empty chunks\n",
    "            continue\n",
    "        \n",
    "        temporary_file_path = f\"temporary/input_{chunk_num}.txt\"\n",
    "        if os.path.exists(temporary_file_path):\n",
    "            with open(temporary_file_path, 'r', encoding=\"utf-8\") as temporary:\n",
    "                token_count = sum(len(line.strip().split()) for line in temporary)\n",
    "                if token_count + len(chunk.split()) + len(timestamp.split()) + 6 > max_token_count:\n",
    "                    chunk_num += 1\n",
    "                    temporary_file_path = f\"temporary/input_{chunk_num}.txt\" # generate a new temporary file path\n",
    "        \n",
    "        with open(temporary_file_path, 'a', encoding=\"utf-8\") as temporary:\n",
    "            temporary.write(f\"[{timestamp},\\\"{chunk}\\\"],\") # write the chunk and timestamp as a JSON array\n",
    "            \n",
    "    chunk_num += 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use ChatGPT to break down the text and meta data into workable chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'temporary'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(newpath):\n\u001b[0;32m      3\u001b[0m     os\u001b[39m.\u001b[39mmakedirs(newpath)\n\u001b[1;32m----> 5\u001b[0m \u001b[39mfor\u001b[39;00m chunk_num, filename \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(os\u001b[39m.\u001b[39;49mlistdir(\u001b[39m'\u001b[39;49m\u001b[39mtemporary\u001b[39;49m\u001b[39m'\u001b[39;49m)):\n\u001b[0;32m      6\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtemporary/input_\u001b[39m\u001b[39m{\u001b[39;00mchunk_num\u001b[39m}\u001b[39;00m\u001b[39m.txt\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m, encoding\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m input_file:\n\u001b[0;32m      7\u001b[0m         data \u001b[39m=\u001b[39m {\n\u001b[0;32m      8\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mgpt-3.5-turbo\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m      9\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mmessages\u001b[39m\u001b[39m\"\u001b[39m: [{\u001b[39m\"\u001b[39m\u001b[39mrole\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39muser\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUsing this list of [start_time, duration, video_transcription]. Respond with only a new list of chunks of the text you as an AI model find appropriately fits in speaking english by combinding list elements and then getting the new start_time by getting the first start_time of that chunk, then get the duration by adding the duration times. Get the new start and duration together to create the new list of [start_time, duration, chunk]. DO NOT give any answer outisde of the format. \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\\"\u001b[39;00m\u001b[39m{\u001b[39;00minput_file\u001b[39m.\u001b[39mread()\u001b[39m}\u001b[39;00m\u001b[39m\\\"\u001b[39;00m\u001b[39m\"\u001b[39m}] \n\u001b[0;32m     10\u001b[0m         }\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'temporary'"
     ]
    }
   ],
   "source": [
    "newpath = os.getcwd() + \"/video_transcription/\"\n",
    "if not os.path.exists(newpath):\n",
    "    os.makedirs(newpath)\n",
    "\n",
    "for chunk_num, filename in enumerate(os.listdir('temporary')):\n",
    "    with open(f\"temporary/input_{chunk_num}.txt\",\"r\", encoding=\"utf-8\") as input_file:\n",
    "        data = {\n",
    "            \"model\": \"gpt-3.5-turbo\",\n",
    "            \"messages\": [{\"role\": \"user\", \"content\": f\"Using this list of [start_time, duration, video_transcription]. Respond with only a new list of chunks of the text you as an AI model find appropriately fits in speaking english by combinding list elements and then getting the new start_time by getting the first start_time of that chunk, then get the duration by adding the duration times. Get the new start and duration together to create the new list of [start_time, duration, chunk]. DO NOT give any answer outisde of the format. \\n\\\"{input_file.read()}\\\"\"}] \n",
    "        }\n",
    "        response = requests.post(url=url, headers=headers, json=data)\n",
    "        created_chunks = response.json().get('choices')[0].get('message').get('content')\n",
    "        with open(f\"video_transcription/input_{chunk_num}.txt\", \"w\", encoding=\"utf-8\") as vidtrans:\n",
    "            vidtrans.write(created_chunks)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get sentiment from ChatGPT and create sentiment analysis file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newpath = os.getcwd() + \"/sentiment_analysis/\"\n",
    "if not os.path.exists(newpath):\n",
    "    os.makedirs(newpath)\n",
    "\n",
    "for chunk_num, filename in enumerate(os.listdir('video_transcription')):\n",
    "    with open(f\"video_transcription/input_{chunk_num}.txt\", \"r\", encoding=\"utf-8\") as input_file:\n",
    "        data = {\n",
    "            \"model\": \"gpt-3.5-turbo\",\n",
    "            \"messages\": [{\"role\": \"user\", \"content\": f\"Using the list [start_time, duration, sentence]. For how '{custom_prompt}' in any definition to the best of your ability as an AI model the sentence is create a score as a float value to the best of your ability as an AI model. Only respond with a new list of [start_time, duration, sentence, float_score]. DO NOT give any answer outisde of the format. \\n\\\"{input_file.read()}\\\"\"}] \n",
    "        }\n",
    "        response = requests.post(url=url, headers=headers, json=data)\n",
    "        sentiment = response.json().get('choices')[0].get('message').get('content')\n",
    "        with open(f\"sentiment_analysis/input_{chunk_num}.txt\",\"w\", encoding=\"utf-8\") as sentanal: # hehe\n",
    "            sentanal.write(sentiment)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Video from choosen segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the audio stream\n",
    "video_stream = pytube.YouTube(vid_url).streams.get_highest_resolution()\n",
    "# Check if audio stream is not None before attempting to download it\n",
    "if video_stream is not None:\n",
    "    # Download the audio stream\n",
    "    video_file = video_stream.download(filename=\"input_video.mp4\").replace(\"\\\\\",\"/\")\n",
    "else:\n",
    "    print(\"No audio stream found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newpath = os.getcwd() + \"/videos/\"\n",
    "if not os.path.exists(newpath):\n",
    "    os.makedirs(newpath)\n",
    "\n",
    "for chunk_num, filename in enumerate(os.listdir('sentiment_analysis')):\n",
    "    with open(f\"sentiment_analysis/input_{chunk_num}.txt\",\"r\", encoding=\"utf-8\") as sentanal: # again hehe\n",
    "        for i, sentlist in enumerate(ast.literal_eval(sentanal.read())):\n",
    "            if(float(sentlist[3]) >= sentiment_score):\n",
    "                output_file_path = f\"videos/output_{i}.mp4\"\n",
    "                split_command = [\"ffmpeg\", \"-framerate\",fps,\"-i\", \"input_video.mp4\", \"-ss\", str(sentlist[0]), \"-t\", str(sentlist[1]), \"-c\", \"copy\", output_file_path]\n",
    "                subprocess.run(split_command, check=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine the videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newpath = os.getcwd() + \"/videos_avi/\"\n",
    "if not os.path.exists(newpath):\n",
    "    os.makedirs(newpath)\n",
    "\n",
    "video_files_with_path = []\n",
    "\n",
    "# List of video files to combine\n",
    "for video_files in os.listdir(\"videos\").sort(key=lambda x: int(re.sub(r'input_(\\d+)\\.mp4', r'\\1', x)))\n",
    "    path = \"videos_avi/\" + video_files.split(\".\")[0] + \".avi\"\n",
    "    commands = ['ffmpeg', '-i', \"videos/\" + video_files, '-c:v', 'copy', path]\n",
    "    video_files_with_path.append(path)\n",
    "\n",
    "\n",
    "# Create a list of commands to concatenate the videos\n",
    "commands = ['ffmpeg', '-i', f'concat:{\"|\".join(video_files_with_path)}', '-c', 'copy', 'output.mp4']\n",
    "\n",
    "# Run the ffmpeg command\n",
    "subprocess.call(commands)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(delete_directories):\n",
    "    newpath = [\"/metadata/\",\"/downloads/\",\"/sentences/\",\"/chunks/\",\"/videos/\",\"/video_transcription\",\"/sentiment_analysis\"]\n",
    "    for i in newpath:\n",
    "        if os.path.exists(os.getcwd() + i):\n",
    "            shutil.rmtree(os.getcwd() + i)\n",
    "\n",
    "    newfilepath = [\"/input.mp4\",\"/input_video.mp4\"]\n",
    "    for i in newfilepath:\n",
    "        if os.path.exists(os.getcwd() + i):\n",
    "            os.remove(os.getcwd() + i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
